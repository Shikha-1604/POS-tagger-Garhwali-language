{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef743312",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_training=\"POS-tagger-Garhwali-language/Data/Training_Data.txt\"\n",
    "file_train=open(root_path_training,\"r\",encoding=\"UTF-8\")\n",
    "train_=file_train.readlines()\n",
    "print(\"number of training sentences : \",len(train_))\n",
    "\n",
    "\n",
    "root_path_test=\"POS-tagger-Garhwali-language/Data/Test_Data.txt\"\n",
    "file_test=open(root_path_test,\"r\",encoding=\"UTF-8\")\n",
    "test_=file_test.readlines()\n",
    "print(\"number of test sentences : \",len(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#----- FUNCTION TO CREATE LIST OF LIST OF TUPLE(WORD,TAG)----------------#\n",
    "###############################################################################\n",
    "def sent_to_labels(data):\n",
    "    content=[]\n",
    "    for sentence in data:\n",
    "        sent=[]\n",
    "        sentence=sentence.strip(\"\\n\")\n",
    "        for wrd_tg in sentence.split(\" \"):\n",
    "            w_t=tuple(wrd_tg.split(\"_\"))\n",
    "            sent.append(w_t)\n",
    "        content.append(sent)\n",
    "    return content    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_\n",
    "data.extend(test_)\n",
    "data = sent_to_labels(data)\n",
    "print(len(data))\n",
    "#data = data.extend(sent_to_labels(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8099d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe \n",
    "stat = {}\n",
    "# No. of Sentences\n",
    "stat[\"No. of Sentences\"] = len(data)\n",
    "\n",
    "#number of words\n",
    "ttl_words = [word[0] for sent in data for word in sent]\n",
    "stat[\"No. of Words\"] = len(ttl_words)\n",
    "\n",
    "#number of unique words\n",
    "stat[\"No. of Unique Words\"] = len(set(ttl_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [word[1] for sent in data for word in sent]\n",
    "tag_freq = pd.Series(tags).value_counts()\n",
    "tag_list = list(tag_freq.index)\n",
    "for tag in tag_list:\n",
    "  stat[tag] = tag_freq[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db584ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsfrequency={}\n",
    "tagsfrequency[\"NN\"] = stat['NN']\n",
    "tagsfrequency[\"VM\"] = stat['VM'] \n",
    "tagsfrequency[\"PSP\"] = stat['PSP']\n",
    "tagsfrequency[\"SYM\"] = stat['SYM']\n",
    "tagsfrequency[\"VAUX\"] = stat['VAUX']\n",
    "tagsfrequency[\"RB\"] = stat['RB']\n",
    "tagsfrequency[\"JJ\"] = stat['JJ']\n",
    "tagsfrequency[\"PRP\"] = stat['PRP']\n",
    "tagsfrequency[\"RP\"] = stat['RP']\n",
    "tagsfrequency[\"NNP\"] = stat['NNP']\n",
    "tagsfrequency[\"CC\"] = stat['CC']\n",
    "tagsfrequency[\"DEM\"] = stat['DEM']\n",
    "tagsfrequency[\"NEG\"] = stat['NEG']\n",
    "tagsfrequency[\"QC\"] = stat['QC']\n",
    "tagsfrequency[\"WQ\"] = stat['WQ']\n",
    "tagsfrequency[\"INJ\"] = stat['INJ']\n",
    "tagsfrequency[\"QF\"] = stat['QF']\n",
    "tagsfrequency[\"UNK\"] = stat['UNK']\n",
    "tagsfrequency[\"RDP\"] = stat['RDP']\n",
    "tagsfrequency[\"NST\"] = stat['NST']\n",
    "tagsfrequency[\"UT\"] = stat['UT']\n",
    "tagsfrequency[\"QO\"] = stat['QO']\n",
    "tagsfrequency[\"ECH\"] = stat['ECH']\n",
    "tagsfrequency[\"INTF\"] = stat['INTF']\n",
    "tagsfrequency[\"COMP\"] = stat['NNC'] + stat['VMC'] + stat['PSPC'] + stat['RBC'] + stat['JJC']  + stat['RPC'] + stat['NNPC'] + stat['QCC'] + stat['QFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd39ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsfrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag and frequency list\n",
    "tag=[]\n",
    "freq=[]\n",
    "for i in tagsfrequency:\n",
    "    tag.append(i)\n",
    "    temp = (tagsfrequency[i]/len(tags))*100\n",
    "    freq.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50cf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "plt.xticks(rotation = 45)\n",
    "plt.bar(tag,freq,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88829d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading training file\n",
    "root_path_training=\"POS-tagger-Garhwali-language/Data/Training_Data.txt\"\n",
    "file_train=open(root_path_training,\"r\",encoding=\"UTF-8\")\n",
    "train_=file_train.readlines()\n",
    "print(\"number of training sentences : \",len(train_))\n",
    "df=pd.DataFrame()\n",
    "df.loc[0,\"Type\"]=\"Train\"\n",
    "words_train=[word for line in train_ for word in line.split()]\n",
    "df.loc[0,\"no of sentences\"]=len(train_)\n",
    "df.loc[0,\"number of words\"]=len(words_train)\n",
    "\n",
    "#unique words\n",
    "wrd_train=[]\n",
    "for wrd in words_train:\n",
    "    wrd_train.append(wrd.split(\"_\")[0])\n",
    "    \n",
    "    \n",
    "df.loc[0,\"Unique words\"]=len(set(wrd_train)) \n",
    "\n",
    "\n",
    "#ambuiguity words\n",
    "wt_train=[]\n",
    "for wrd in words_train:\n",
    "    wt_train.append(tuple(wrd.split(\"_\")))\n",
    "    \n",
    "count=0\n",
    "wrd_tag_dict={}\n",
    "for word in list(set(wrd_train)):\n",
    "    tags=[]\n",
    "    for with_tag in wt_train:\n",
    "        if(word==with_tag[0]):\n",
    "            tags.append(with_tag[1])\n",
    "    wrd_tag_dict[word]=set(tags)        \n",
    "            \n",
    "            \n",
    "        \n",
    "count=0\n",
    "for words in wrd_tag_dict:\n",
    "    if(len(wrd_tag_dict[words])>1):\n",
    "        for in_train in wrd_train:\n",
    "            if(words == in_train):\n",
    "                count=count+1\n",
    "      \n",
    "    \n",
    "w={}\n",
    "for words in wrd_tag_dict:\n",
    "    count=0\n",
    "    if(len(wrd_tag_dict[words])>1):\n",
    "        for in_train in wrd_train:\n",
    "            if(words == in_train):\n",
    "                count=count+1\n",
    "        w[words]=count            \n",
    "\n",
    "summ=0\n",
    "for i in w:\n",
    "    summ=summ+w[i]\n",
    "    \n",
    "df.loc[0,\"% Ambiguous words\"]=summ/len(words_train)        \n",
    "\n",
    "\n",
    "\n",
    "# Number of Ambiguous words\n",
    "wt_train=[]\n",
    "for wrd in words_train:\n",
    "    wt_train.append(tuple(wrd.split(\"_\")))\n",
    "    \n",
    "    \n",
    "count=0\n",
    "wrd_tag_dict={}\n",
    "for word in list(set(wrd_train)):\n",
    "    tags=[]\n",
    "    for with_tag in wt_train:\n",
    "        if(word==with_tag[0]):\n",
    "            tags.append(with_tag[1])\n",
    "    wrd_tag_dict[word]=set(tags)        \n",
    "            \n",
    "            \n",
    "        \n",
    "count=0\n",
    "for i in wrd_tag_dict:\n",
    "    if(len(wrd_tag_dict[i])>1):\n",
    "        for word in wrd_train:\n",
    "            if(i == word):\n",
    "                count=count+1        \n",
    "        \n",
    "        \n",
    "df.loc[0,\"Ambuiguity words\"]=count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fedd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading test file\n",
    "root_path_test=\"POS-tagger-Garhwali-language/Data/Test_Data.txt\"\n",
    "file_test=open(root_path_test,\"r\",encoding=\"UTF-8\")\n",
    "test_=file_test.readlines()\n",
    "print(\"number of test sentences : \",len(test_))\n",
    "\n",
    "df.loc[1,\"Type\"]=\"Test\"\n",
    "words_test=[word for line in test_ for word in line.split()]\n",
    "df.loc[1,\"no of sentences\"]=len(test_)\n",
    "df.loc[1,\"number of words\"]=len(words_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#unique words\n",
    "wrd_test=[]\n",
    "for wrd in words_test:\n",
    "    wrd_test.append(wrd.split(\"_\")[0])\n",
    "    \n",
    "    \n",
    "df.loc[1,\"Unique words\"]=len(set(wrd_test)) \n",
    "\n",
    "\n",
    "#ambuiguity words\n",
    "wt_test=[]\n",
    "for wrd in words_test:\n",
    "    wt_test.append(tuple(wrd.split(\"_\")))\n",
    "    \n",
    "count=0\n",
    "wrd_tag_dict_test={}\n",
    "for word in list(set(wrd_test)):\n",
    "    tags=[]\n",
    "    for with_tag in wt_test:\n",
    "        if(word==with_tag[0]):\n",
    "            tags.append(with_tag[1])\n",
    "    wrd_tag_dict_test[word]=set(tags)        \n",
    "            \n",
    " \n",
    "#total ambiguious words\n",
    "count=0\n",
    "for words in wrd_tag_dict_test:\n",
    "    if(len(wrd_tag_dict_test[words])>1):\n",
    "        for in_test in wrd_test:\n",
    "            if(words == in_test):\n",
    "                count=count+1\n",
    "\n",
    "                \n",
    "w={}\n",
    "for words in wrd_tag_dict_test:\n",
    "    count=0\n",
    "    if(len(wrd_tag_dict_test[words])>1):\n",
    "        for in_test in wrd_test:\n",
    "            if(words == in_test):\n",
    "                count=count+1\n",
    "        w[words]=count            \n",
    "\n",
    "summ=0\n",
    "for i in w:\n",
    "    summ=summ+w[i]\n",
    "    \n",
    "df.loc[1,\"% Ambiguous words\"]=summ/len(words_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#test words\n",
    "wrd_test=[]\n",
    "for wrd in words_test:\n",
    "    wrd_test.append(wrd.split(\"_\")[0])\n",
    "    \n",
    "    \n",
    "wt_test=[]\n",
    "for wrd in words_test:\n",
    "    wt_test.append(tuple(wrd.split(\"_\")))\n",
    "    \n",
    "    \n",
    "    \n",
    "count=0\n",
    "wrd_tag_dict={}\n",
    "for word in list(set(wrd_test)):\n",
    "    tags=[]\n",
    "    for with_tag in wt_test:\n",
    "        if(word==with_tag[0]):\n",
    "            tags.append(with_tag[1])\n",
    "    wrd_tag_dict[word]=set(tags)        \n",
    "            \n",
    "            \n",
    "count=0\n",
    "for i in wrd_tag_dict:\n",
    "    if(len(wrd_tag_dict[i])>1):\n",
    "        count=count+1           \n",
    "        \n",
    "        \n",
    "df.loc[1,\"Ambuiguity words\"]=count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02383b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9662cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d4744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
