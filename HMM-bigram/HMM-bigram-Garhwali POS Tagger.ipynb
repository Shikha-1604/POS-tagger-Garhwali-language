{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d58b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91104dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_training=\"POS-tagger-Garhwali-language/Data/Training_Data.txt\"\n",
    "file_train=open(root_path_training,\"r\",encoding=\"UTF-8\")\n",
    "train_=file_train.readlines()\n",
    "print(\"number of training sentences : \",len(train_))\n",
    "\n",
    "\n",
    "root_path_test=\"POS-tagger-Garhwali-language/Data/Test_Data.txt\"\n",
    "file_test=open(root_path_test,\"r\",encoding=\"UTF-8\")\n",
    "test_=file_test.readlines()\n",
    "print(\"number of test sentences : \",len(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#----- FUNCTION TO CREATE LIST OF LIST OF TUPLE(WORD,TAG)----------------#\n",
    "###############################################################################\n",
    "def sent_to_labels(data):\n",
    "    content=[]\n",
    "    for sentence in data:\n",
    "        sent=[]\n",
    "        sentence=sentence.strip(\"\\n\")\n",
    "        for wrd_tg in sentence.split(\" \"):\n",
    "            w_t=tuple(wrd_tg.split(\"_\"))\n",
    "            sent.append(w_t)\n",
    "        content.append(sent)\n",
    "    return content     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#----- FUNCTION TO CREATE LIST OF LIST OF WORD----------------#\n",
    "###############################################################################\n",
    "def validate_sentences(validate_text):\n",
    "    validate=[]\n",
    "    for lines in validate_text:\n",
    "        sent=[]\n",
    "        for tagged in lines.split():\n",
    "            wrd=tagged.split(\"_\")[0]\n",
    "            sent.append(wrd)\n",
    "        validate.append(sent)\n",
    "    return validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aee4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#---- CALLING FUNCITON TO CREATE THE TRAIN DATA LIST [[(W1,T1),(W2,T2)]]\n",
    "############################################################################\n",
    "train_data=sent_to_labels(train_)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#---- CALLING FUNCITON TO CREATE THE VALIDATE DATA LIST [[(W1,T1),(W2,T2)]]\n",
    "############################################################################\n",
    "test_data=sent_to_labels(test_)\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "#---- CALLING FUNCITON TO CREATE THE LIST OF SENTENCE TO VALIDATE DATA ON [[\"W1\",\"W2\"....]]\n",
    "############################################################################################\n",
    "\n",
    "test_sent=validate_sentences(test_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the hmm-bigram model\n",
    "\n",
    "tagger=nltk.HiddenMarkovModelTagger._train(train_data,max_iterations=500,verbose=True)\n",
    "\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating tagger\n",
    "tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde84a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b85f80",
   "metadata": {},
   "source": [
    "# **Added Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sent = tagger.tag_sents(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f9a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ce15b2",
   "metadata": {},
   "source": [
    "# **1. Reduplicative Tag** \n",
    "*two consecutive occurrence of the word or the word-word form. Second occurrence will be tagged as RDP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tagged_sent:\n",
    "    ret=len(ts)-2\n",
    "    for w in range(ret):\n",
    "        if(ts[w][0]==ts[w+1][0]):\n",
    "            ts[w+1]=list(ts[w])\n",
    "            print(ts[w][0],ts[w+1][0])\n",
    "            ts[w+1][1]='RDP'\n",
    "            ts[w+1]=tuple(ts[w+1])\n",
    "        if(ts[w][0]==ts[w+2][0] and ts[w+1][0]=='-'):\n",
    "            #print(ts[w][0],ts[w+2][0])\n",
    "            ts[w+2]=list(ts[w+2])\n",
    "            ts[w+2][1]='RDP'\n",
    "            ts[w+2]=tuple(ts[w+2])\n",
    "            \n",
    "\n",
    "\n",
    "# ACCURACY - RDP feature added\n",
    "list_manual=[word[1] for sent in tagged_sent for word in sent]\n",
    "list_tagger=[word[1] for sent in test_data for word in sent]\n",
    "matrix=confusion_matrix(list_tagger,list_manual,labels=list(set(list_tagger)))\n",
    "df=pd.DataFrame(matrix,index=list(set(list_tagger)),columns=list(set(list_tagger)))\n",
    "summ=0\n",
    "acuuracy=0\n",
    "for tag in list(set(list_tagger)):\n",
    "    summ+=df[tag][tag]\n",
    "    \n",
    "total = len([word for sent in tagged_sent for word in sent])\n",
    "accuracy=summ/total       \n",
    "\n",
    "print(accuracy)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72326ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747c707b",
   "metadata": {},
   "source": [
    "# **2. Unknown Tag**\n",
    "\n",
    "*words only tagged as unknown in the training set will be tagged as UNK in the test set also*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words only tagged as UNK in the train data will be tagged as UNK  \n",
    "\n",
    "unknown_wrd=train_data\n",
    "unknown_wrd=[word[0] for sent in train_data for word in sent if(word[1]=='UNK')]\n",
    "allwrd=[word for sent in train_data for word in sent]\n",
    "unk_tags={}\n",
    "\n",
    "#list of unknown words\n",
    "for unk in unknown_wrd:\n",
    "    temp=[]\n",
    "    for word in allwrd:\n",
    "        if(unk==word[0]):\n",
    "            temp.append(word[1])\n",
    "    unk_tags[unk]=list(set(temp))        \n",
    "unknown_wrd=[]\n",
    "for word in unk_tags:\n",
    "    if(unk_tags[word]==['UNK']):\n",
    "        unknown_wrd.append(word)\n",
    "        \n",
    "for sent in tagged_sent:\n",
    "    for word in sent:\n",
    "        if(word[0] in unknown_wrd):\n",
    "            word=list(word)\n",
    "            word[1]=\"UNK\"\n",
    "            word=tuple(word)\n",
    "            \n",
    "            \n",
    "            \n",
    "## ACCURACY CALCULATION\n",
    "list_manual=[word[1] for sent in tagged_sent for word in sent]\n",
    "list_tagger=[word[1] for sent in test_data for word in sent]\n",
    "matrix=confusion_matrix(list_tagger,list_manual,labels=list(set(list_tagger)))\n",
    "df=pd.DataFrame(matrix,index=list(set(list_tagger)),columns=list(set(list_tagger)))\n",
    "summ=0\n",
    "acuuracy=0\n",
    "for tag in list(set(list_tagger)):\n",
    "    summ+=df[tag][tag]\n",
    "\n",
    "total = len([word for sent in tagged_sent for word in sent])\n",
    "accuracy=summ/total   \n",
    "print(accuracy)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7407746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0dd0b9",
   "metadata": {},
   "source": [
    "# **3. Symbol Tag**\n",
    "*All the special characters except for the numeric characters will be tagged as SYM*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd81f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Characters in the data will be tagged as SYM\n",
    "\n",
    "sym=[word[0] for sent in train_data for word in sent if(word[1] == 'SYM')]\n",
    "sym=list(set(sym))\n",
    "for sent in tagged_sent:\n",
    "    leng=len(sent)-1\n",
    "    for w in range(leng):\n",
    "        if(sent[w][1]=='SYM'):\n",
    "            if not (sent[w][0] in sym):\n",
    "                \n",
    "                \n",
    "                tag=tagger.tag([sent[w][0]])\n",
    "                sent[w]=list(sent[w])\n",
    "                sent[w][1]=tag[0][1]\n",
    "                sent[w]=tuple(sent[w])\n",
    "              \n",
    "\n",
    "## ACCURACY CALCULATION\n",
    "list_manual=[word[1] for sent in tagged_sent for word in sent]\n",
    "list_tagger=[word[1] for sent in test_data for word in sent]\n",
    "matrix=confusion_matrix(list_tagger,list_manual,labels=list(set(list_tagger)))\n",
    "df=pd.DataFrame(matrix,index=list(set(list_tagger)),columns=list(set(list_tagger)))\n",
    "summ=0\n",
    "acuuracy=0\n",
    "for tag in list(set(list_tagger)):\n",
    "    summ+=df[tag][tag]\n",
    "    \n",
    "    \n",
    "total = len([word for sent in tagged_sent for word in sent])\n",
    "accuracy=summ/total   \n",
    "\n",
    "print(accuracy)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83460697",
   "metadata": {},
   "source": [
    "# **4. Verb Tag**\n",
    "*words containing entire word which tagged as NN and ending with ['ली' , 'लि' , 'नि' , 'नी'  , 'ण' , 'णी' , 'णि ' , ' ु', ' ू' ]   will tagged as VM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_words = [word[0] for sent in train_data for word in sent if(word[1]=='NN')]\n",
    "# all_wrd= [word for sent in train_data for word in sent]\n",
    "# NV_words = []\n",
    "# for word in all_wrd:\n",
    "#     if(word[0] in NN_words):\n",
    "#         if(word[1] == 'NN' and (word[1] == 'VM' or word[1] == 'VAUX')):\n",
    "#             NV_words.append(word[0])\n",
    "\n",
    "            \n",
    "# ending_diacritic=['ली' , 'लि' , 'नि' , 'नी'  , 'ण' , 'णी' , 'णि ' , ' ु', ' ू' ]            \n",
    "# for sent in tagged_sent:\n",
    "#     for word in sent:\n",
    "#         Val=0\n",
    "#         for w in NV_words:\n",
    "#             if(word[0] in w):\n",
    "#                 Val=1\n",
    "            \n",
    "#         if(Val == 1):\n",
    "#             if(word[-2:] in ending_diacritic or word[-1] in ending_diacritic):\n",
    "#                 word=list(word)\n",
    "#                 word[1]='VM'\n",
    "#                 word=tuple(word)\n",
    "\n",
    "\n",
    "# ## ACCURACY CALCULATION\n",
    "# list_manual=[word[1] for sent in tagged_sent for word in sent]\n",
    "# list_tagger=[word[1] for sent in test_data for word in sent]\n",
    "# matrix=confusion_matrix(list_tagger,list_manual,labels=list(set(list_tagger)))\n",
    "# df=pd.DataFrame(matrix,index=list(set(list_tagger)),columns=list(set(list_tagger)))\n",
    "# summ=0\n",
    "# acuuracy=0\n",
    "# for tag in list(set(list_tagger)):\n",
    "#     summ+=df[tag][tag]\n",
    "#     #print(tag,summ)\n",
    "\n",
    "# total = len([word for sent in tagged_sent for word in sent])\n",
    "# accuracy=summ/total   \n",
    "\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750ae41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad74ca2a",
   "metadata": {},
   "source": [
    "# **5.Auxiliary Words**\n",
    "*words after Verb will be tagged as Auxiliary Verb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of words that are tagged as VERB or VAUX\n",
    "# v_wrd=train_data\n",
    "# v_wrd=[word[0] for sent in train_data for word in sent if(word[1]=='VERB' or word[1]=='VAUX')]\n",
    "# allwrd=[word for sent in train_data for word in sent]\n",
    "# v_tags={}\n",
    "\n",
    "# #list of verb or vaux words\n",
    "# for v in v_wrd:\n",
    "#     temp=[]\n",
    "#     for word in allwrd:\n",
    "#         if(v==word[0]):\n",
    "#             temp.append(word[1])\n",
    "#     v_tags[v]=list(set(temp))        \n",
    "\n",
    "# vv_words=[]    \n",
    "# for word in v_tags:\n",
    "#     if(len(v_tags[word]) <= 2):\n",
    "#         if(v_tags[word] in ['VAUX','VM']):\n",
    "#             vv_words.append(word)\n",
    "            \n",
    "# for sent in tagged_sent:\n",
    "#     leng=len(sent)-1\n",
    "#     for w in range(leng):\n",
    "#         if(sent[w][1] in ['VM','VAUX'] and sent[w+1][0] in vv_words):\n",
    "#             sent[w+1]=list(sent[w+1])\n",
    "#             sent[w+1][1]='VAUX'\n",
    "#             sent[w+1]=tuple(sent[w+1])\n",
    "\n",
    "\n",
    "\n",
    "# ## ACCURACY CALCULATION\n",
    "# list_manual=[word[1] for sent in tagged_sent for word in sent]\n",
    "# list_tagger=[word[1] for sent in test_data for word in sent]\n",
    "# matrix=confusion_matrix(list_tagger,list_manual,labels=list(set(list_tagger)))\n",
    "# df=pd.DataFrame(matrix,index=list(set(list_tagger)),columns=list(set(list_tagger)))\n",
    "# summ=0\n",
    "# acuuracy=0\n",
    "# for tag in list(set(list_tagger)):\n",
    "#     summ+=df[tag][tag]\n",
    "#     print(tag,summ)\n",
    "\n",
    "\n",
    "# total = len([word for sent in tagged_sent for word in sent])\n",
    "# accuracy=summ/total \n",
    "\n",
    "\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29446e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
